{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import math\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from algos.annealed_smc import AnnealedSMC\n",
    "from utils import build_relaxed_single_token_prior, build_suffix_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2').to(device, dtype=torch.float32)\n",
    "model.eval()\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "suffix = \" quick dog jumped over the lazy fox\"\n",
    "suffix_ids = tokenizer.encode(suffix, add_special_tokens=False)\n",
    "\n",
    "log_prior, grad_log_prior, sample_prior = build_relaxed_single_token_prior(model, tokenizer, device)\n",
    "log_like, grad_log_like = build_suffix_likelihood(model, tokenizer, suffix_ids, device)\n",
    "\n",
    "def log_target(x, sigma):\n",
    "    with torch.no_grad():\n",
    "        return log_like(x) + log_prior(x, sigma)\n",
    "\n",
    "def grad_log_target(x, sigma):\n",
    "    with torch.no_grad():\n",
    "        return grad_log_like(x) + grad_log_prior(x, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \" quick dog jumped over the lazy fox\"\n",
    "suffix_ids = tokenizer.encode(suffix, add_special_tokens=False)\n",
    "\n",
    "solution = \"The\"\n",
    "solution_ids = tokenizer.encode(solution, add_special_tokens=False)\n",
    "solution_latents = model.transformer.wte(torch.tensor(solution_ids, device=device)).detach()\n",
    "\n",
    "log_prior, grad_log_prior, sample_prior = build_relaxed_single_token_prior(model, tokenizer, device)\n",
    "log_like, grad_log_like = build_suffix_likelihood(model, tokenizer, suffix_ids, device)\n",
    "\n",
    "def log_target(x, sigma):\n",
    "    with torch.no_grad():\n",
    "        return log_like(x) + log_prior(x, sigma)\n",
    "        # return log_prior(x, sigma)\n",
    "\n",
    "def grad_log_target(x, sigma):\n",
    "    with torch.no_grad():\n",
    "        return grad_log_like(x) + grad_log_prior(x, sigma)\n",
    "        # return grad_log_prior(x, sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7adebf2404c45e6ae9b2cdf8bf1c1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running SMC (ESS = 16):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_0: 10.0\n",
      "new_index: 0, curr_index: 0\n",
      "solution: -4.5873e+01, -2.4742e+03\n",
      "    soDelivery: -4.8051e+01, -2.8574e+03\n",
      "    ãĤ´ãĥ³    : -5.3297e+01, -2.8350e+03\n",
      "    soDelivery: -4.8220e+01, -2.8556e+03\n",
      "    li        : -5.1999e+01, -2.8492e+03\n",
      "    soDelivery: -4.8080e+01, -2.8617e+03\n",
      "    english   : -4.8220e+01, -2.8569e+03\n",
      "    soDelivery: -4.9497e+01, -2.8548e+03\n",
      "    english   : -4.8578e+01, -2.8634e+03\n",
      "    soDelivery: -4.8697e+01, -2.8584e+03\n",
      "    soDelivery: -4.7277e+01, -2.8604e+03\n",
      "    soDelivery: -4.8196e+01, -2.8591e+03\n",
      "    english   : -4.7442e+01, -2.8619e+03\n",
      "    soDelivery: -4.7986e+01, -2.8570e+03\n",
      "    soDelivery: -4.9360e+01, -2.8627e+03\n",
      "    soDelivery: -4.7202e+01, -2.8559e+03\n",
      "    urous     : -5.2685e+01, -2.8555e+03\n",
      "sigma_1: 9.75390625\n",
      "new_index: 2, curr_index: 0\n",
      "solution: -4.5873e+01, -2.4551e+03\n",
      "    soDelivery: -4.8146e+01, -2.8588e+03\n",
      "    ãĤ´ãĥ³    : -5.1677e+01, -2.8355e+03\n",
      "    soDelivery: -4.7760e+01, -2.8562e+03\n",
      "    li        : -5.1847e+01, -2.8495e+03\n",
      "    Sham      : -4.8186e+01, -2.8625e+03\n",
      "    english   : -4.8682e+01, -2.8617e+03\n",
      "    soDelivery: -4.9768e+01, -2.8603e+03\n",
      "    english   : -4.9216e+01, -2.8573e+03\n",
      "    abre      : -4.7563e+01, -2.8548e+03\n",
      "    soDelivery: -4.6735e+01, -2.8645e+03\n",
      "    english   : -4.8074e+01, -2.8605e+03\n",
      "    soDelivery: -4.7005e+01, -2.8594e+03\n",
      "    soDelivery: -4.7711e+01, -2.8534e+03\n",
      "    soDelivery: -5.0496e+01, -2.8624e+03\n",
      "    soDelivery: -4.6686e+01, -2.8557e+03\n",
      "    andise    : -5.2641e+01, -2.8577e+03\n",
      "sigma_2: 9.75390625\n",
      "new_index: 2, curr_index: 2\n",
      "solution: -4.5873e+01, -2.4551e+03\n",
      "    andise    : -5.1535e+01, -2.8531e+03\n",
      "    english   : -4.9013e+01, -2.8593e+03\n",
      "    andise    : -5.2706e+01, -2.8559e+03\n",
      "    ãĤ´ãĥ³    : -5.0999e+01, -2.8314e+03\n",
      "    english   : -4.8785e+01, -2.8640e+03\n",
      "    english   : -4.8473e+01, -2.8612e+03\n",
      "    english   : -4.7553e+01, -2.8615e+03\n",
      "    li        : -5.1682e+01, -2.8478e+03\n",
      "    urous     : -5.1971e+01, -2.8525e+03\n",
      "    soDelivery: -4.7954e+01, -2.8658e+03\n",
      "    soDelivery: -4.7152e+01, -2.8571e+03\n",
      "    english   : -4.7264e+01, -2.8531e+03\n",
      "    soDelivery: -4.6672e+01, -2.8580e+03\n",
      "    afety     : -4.7277e+01, -2.8548e+03\n",
      "    soDelivery: -4.7802e+01, -2.8504e+03\n",
      "    soDelivery: -4.8270e+01, -2.8628e+03\n",
      "sigma_3: 9.54018783569336\n",
      "new_index: 3, curr_index: 2\n",
      "solution: -4.5873e+01, -2.4380e+03\n",
      "    ui        : -5.1748e+01, -2.8515e+03\n",
      "    english   : -4.9489e+01, -2.8585e+03\n",
      "    andise    : -5.1887e+01, -2.8559e+03\n",
      "    ãĤ´ãĥ³    : -5.1417e+01, -2.8308e+03\n",
      "    english   : -4.9445e+01, -2.8743e+03\n",
      "    english   : -4.7687e+01, -2.8624e+03\n",
      "    english   : -4.8033e+01, -2.8570e+03\n",
      "    Ġtoast    : -5.1661e+01, -2.8478e+03\n",
      "    urous     : -5.1055e+01, -2.8502e+03\n",
      "    soDelivery: -4.7535e+01, -2.8659e+03\n",
      "    soDelivery: -4.7282e+01, -2.8550e+03\n",
      "    english   : -4.7623e+01, -2.8493e+03\n",
      "    soDelivery: -4.6966e+01, -2.8616e+03\n",
      "    afety     : -4.7631e+01, -2.8491e+03\n",
      "    soDelivery: -4.7684e+01, -2.8518e+03\n",
      "    soDelivery: -4.8452e+01, -2.8650e+03\n",
      "sigma_4: 9.54018783569336\n",
      "new_index: 3, curr_index: 3\n",
      "solution: -4.5873e+01, -2.4380e+03\n",
      "    abre      : -4.8174e+01, -2.8519e+03\n",
      "    Ġtoast    : -5.2016e+01, -2.8438e+03\n",
      "    soDelivery: -4.7347e+01, -2.8441e+03\n",
      "    english   : -4.7263e+01, -2.8595e+03\n",
      "    Ġtoast    : -5.2200e+01, -2.8486e+03\n",
      "    soDelivery: -4.7009e+01, -2.8555e+03\n",
      "    afety     : -4.6992e+01, -2.8608e+03\n",
      "    soDelivery: -4.8830e+01, -2.8686e+03\n",
      "    abre      : -4.7674e+01, -2.8473e+03\n",
      "    soDelivery: -4.8408e+01, -2.8615e+03\n",
      "    soDelivery: -4.7568e+01, -2.8613e+03\n",
      "    soDelivery: -4.7597e+01, -2.8656e+03\n",
      "    soDelivery: -4.7536e+01, -2.8494e+03\n",
      "    hack      : -4.6536e+01, -2.8535e+03\n",
      "    Ġtoast    : -5.2036e+01, -2.8448e+03\n",
      "    soDelivery: -4.7449e+01, -2.8697e+03\n",
      "sigma_5: 9.248286884278059\n",
      "new_index: 4, curr_index: 3\n",
      "solution: -4.5873e+01, -2.4142e+03\n",
      "    abre      : -4.8528e+01, -2.8542e+03\n",
      "    Ġtoast    : -5.1599e+01, -2.8457e+03\n",
      "    hack      : -4.7548e+01, -2.8494e+03\n",
      "    english   : -4.6787e+01, -2.8615e+03\n",
      "    Ġtoast    : -5.2117e+01, -2.8540e+03\n",
      "    soDelivery: -4.6835e+01, -2.8596e+03\n",
      "    soDelivery: -4.8300e+01, -2.8667e+03\n",
      "    soDelivery: -4.8992e+01, -2.8674e+03\n",
      "    english   : -4.6380e+01, -2.8537e+03\n",
      "    soDelivery: -4.8483e+01, -2.8649e+03\n",
      "    afety     : -4.7749e+01, -2.8651e+03\n",
      "    soDelivery: -4.7621e+01, -2.8748e+03\n",
      "    soDelivery: -4.7024e+01, -2.8505e+03\n",
      "    hack      : -4.6175e+01, -2.8530e+03\n",
      "    Ġtoast    : -5.2134e+01, -2.8472e+03\n",
      "    soDelivery: -4.8072e+01, -2.8693e+03\n",
      "sigma_6: 9.248286884278059\n",
      "new_index: 4, curr_index: 4\n",
      "solution: -4.5873e+01, -2.4142e+03\n",
      "    Ġtoast    : -5.2044e+01, -2.8579e+03\n",
      "    hack      : -4.7381e+01, -2.8494e+03\n",
      "    Ġtoast    : -5.1475e+01, -2.8390e+03\n",
      "    Ġtoast    : -5.1723e+01, -2.8523e+03\n",
      "    Ġtoast    : -5.2379e+01, -2.8496e+03\n",
      "    soDelivery: -4.8179e+01, -2.8738e+03\n",
      "    soDelivery: -4.8580e+01, -2.8611e+03\n",
      "    Ġtoast    : -5.1362e+01, -2.8512e+03\n",
      "    soDelivery: -4.8858e+01, -2.8605e+03\n",
      "    Ġtoast    : -5.1490e+01, -2.8411e+03\n",
      "    hack      : -4.7195e+01, -2.8540e+03\n",
      "    hack      : -4.6283e+01, -2.8449e+03\n",
      "    Ġtoast    : -5.1817e+01, -2.8505e+03\n",
      "    soDelivery: -4.6555e+01, -2.8474e+03\n",
      "    english   : -4.8223e+01, -2.8623e+03\n",
      "    soDelivery: -4.8602e+01, -2.8631e+03\n",
      "sigma_7: 8.982472951483942\n",
      "new_index: 5, curr_index: 4\n",
      "solution: -4.5873e+01, -2.3918e+03\n",
      "    Ġtoast    : -5.2130e+01, -2.8607e+03\n",
      "    hack      : -4.6898e+01, -2.8539e+03\n",
      "    Ġtoast    : -5.1991e+01, -2.8377e+03\n",
      "    li        : -5.1413e+01, -2.8516e+03\n",
      "    Ġtoast    : -5.2822e+01, -2.8499e+03\n",
      "    soDelivery: -4.7477e+01, -2.8767e+03\n",
      "    soDelivery: -4.7504e+01, -2.8727e+03\n",
      "    Ġtoast    : -5.1573e+01, -2.8554e+03\n",
      "    soDelivery: -4.8376e+01, -2.8702e+03\n",
      "    Ġtoast    : -5.1552e+01, -2.8394e+03\n",
      "    english   : -4.6694e+01, -2.8602e+03\n",
      "    hack      : -4.6837e+01, -2.8425e+03\n",
      "    Ġtoast    : -5.1683e+01, -2.8526e+03\n",
      "    soDelivery: -4.6847e+01, -2.8520e+03\n",
      "    english   : -4.8957e+01, -2.8723e+03\n",
      "    soDelivery: -4.8392e+01, -2.8672e+03\n",
      "sigma_8: 8.982472951483942\n",
      "new_index: 5, curr_index: 5\n",
      "solution: -4.5873e+01, -2.3918e+03\n",
      "    english   : -4.6563e+01, -2.8427e+03\n",
      "    soDelivery: -4.7345e+01, -2.8385e+03\n",
      "    Ġtoast    : -5.1751e+01, -2.8355e+03\n",
      "    Ġtoast    : -5.1492e+01, -2.8326e+03\n",
      "    Ġtoast    : -5.1569e+01, -2.8326e+03\n",
      "    Ġtoast    : -5.1414e+01, -2.8378e+03\n",
      "    li        : -5.2666e+01, -2.8549e+03\n",
      "    Ġtoast    : -5.1756e+01, -2.8401e+03\n",
      "    hack      : -4.7159e+01, -2.8442e+03\n",
      "    Ġtoast    : -5.1400e+01, -2.8490e+03\n",
      "    Ġtoast    : -5.1688e+01, -2.8417e+03\n",
      "    soDelivery: -4.6564e+01, -2.8501e+03\n",
      "    soDelivery: -4.8024e+01, -2.8686e+03\n",
      "    hack      : -4.7132e+01, -2.8480e+03\n",
      "    Ġtoast    : -5.1744e+01, -2.8603e+03\n",
      "    Ġtoast    : -5.1961e+01, -2.8376e+03\n",
      "sigma_9: 8.701839136783335\n",
      "new_index: 7, curr_index: 5\n",
      "solution: -4.5873e+01, -2.3674e+03\n",
      "    saf       : -4.6836e+01, -2.8439e+03\n",
      "    soDelivery: -4.6555e+01, -2.8428e+03\n",
      "    Ġtoast    : -5.2120e+01, -2.8328e+03\n",
      "    Ġtoast    : -5.1697e+01, -2.8292e+03\n",
      "    Ġtoast    : -5.1150e+01, -2.8343e+03\n",
      "    Ġtoast    : -5.0877e+01, -2.8411e+03\n",
      "    li        : -5.2731e+01, -2.8558e+03\n",
      "    Ġtoast    : -5.2113e+01, -2.8394e+03\n",
      "    english   : -4.7256e+01, -2.8504e+03\n",
      "    li        : -5.1569e+01, -2.8529e+03\n",
      "    Ġtoast    : -5.0478e+01, -2.8429e+03\n",
      "    ï¸        : -4.6383e+01, -2.8567e+03\n",
      "    soDelivery: -4.8554e+01, -2.8733e+03\n",
      "    hack      : -4.7157e+01, -2.8505e+03\n",
      "    Ġtoast    : -5.1827e+01, -2.8660e+03\n",
      "    Ġtoast    : -5.2139e+01, -2.8443e+03\n",
      "sigma_10: 8.701839136783335\n",
      "new_index: 7, curr_index: 7\n",
      "solution: -4.5873e+01, -2.3674e+03\n",
      "    hack      : -4.6989e+01, -2.8424e+03\n",
      "    Ġtoast    : -5.2006e+01, -2.8434e+03\n",
      "    Ġtoast    : -5.0363e+01, -2.8323e+03\n",
      "    Ġtoast    : -5.2148e+01, -2.8348e+03\n",
      "    hack      : -4.7206e+01, -2.8511e+03\n",
      "    Ġtoast    : -5.2428e+01, -2.8424e+03\n",
      "    Ġtoast    : -5.1913e+01, -2.8272e+03\n",
      "    Medic     : -4.7238e+01, -2.8354e+03\n",
      "    english   : -4.7175e+01, -2.8419e+03\n",
      "    saf       : -4.7227e+01, -2.8425e+03\n",
      "    li        : -5.1457e+01, -2.8292e+03\n",
      "    Ġtoast    : -5.1769e+01, -2.8434e+03\n",
      "    Ġtoast    : -5.2158e+01, -2.8540e+03\n",
      "    Ġtoast    : -5.1906e+01, -2.8702e+03\n",
      "    english   : -4.6969e+01, -2.8500e+03\n",
      "    Ġtoast    : -5.1608e+01, -2.8283e+03\n",
      "sigma_11: 8.476199318322884\n"
     ]
    }
   ],
   "source": [
    "N = 16\n",
    "d = 768 # gpt2 embedding dimension\n",
    "sigma0 = 8.0\n",
    "sigma_target = 1.0\n",
    "\n",
    "def sample_initial_particles(N, d):\n",
    "    return sample_prior(N, sigma0)\n",
    "\n",
    "def initial_logp(x):\n",
    "    return log_prior(x, sigma0)\n",
    "\n",
    "def project_to_vocab(\n",
    "    z: torch.Tensor,\n",
    "    model: GPT2LMHeadModel,\n",
    "    tokenizer: GPT2Tokenizer,\n",
    "    device: torch.device,\n",
    ") -> List[str]:\n",
    "    embedding_matrix = model.transformer.wte.weight.detach()\n",
    "    distances = torch.cdist(z, embedding_matrix)          # (N,V)\n",
    "    token_idxs = distances.argmin(dim=1)                  # (N,)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(token_idxs)\n",
    "    return tokens\n",
    "\n",
    "def debug_log_tokens(z, sigma):\n",
    "    solution_likelihood = log_like(solution_latents)\n",
    "    solution_prior = log_prior(solution_latents, sigma)\n",
    "    print(f\"solution: {solution_likelihood.item():.4e}, {solution_prior.item():.4e}\")\n",
    "\n",
    "    vocabs = project_to_vocab(z, model, tokenizer, device)\n",
    "    likelihoods = log_like(z)\n",
    "    priors = log_prior(z, sigma)\n",
    "    for vocab, likelihood, prior in zip(vocabs, likelihoods, priors):\n",
    "        print(f\"    {vocab[:10] + ' ' * (10 - len(vocab[:10]))}: {likelihood:.4e}, {prior:.4e}\")\n",
    "\n",
    "sampler = AnnealedSMC(\n",
    "    N=N,\n",
    "    x_dim=d,\n",
    "    sigma_0=sigma0,\n",
    "    sigma_target=sigma_target,\n",
    "    alpha=0.5,\n",
    "    mala_step_size=lambda sigma: min(0.1, 0.5 * sigma),\n",
    "    mala_steps=128,\n",
    "    ess_min_frac=0.8,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "final_particles = sampler.run(\n",
    "    init_sampler=sample_initial_particles,\n",
    "    init_logp=initial_logp,\n",
    "    log_target=log_target,\n",
    "    grad_log_target=grad_log_target,\n",
    "    debug_logger=debug_log_tokens\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
