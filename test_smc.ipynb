{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import math\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from algos.annealed_smc import AnnealedSMC\n",
    "from utils import build_relaxed_single_token_prior, build_suffix_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2').to(device, dtype=torch.float32)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "suffix = \" went to the shop\"\n",
    "suffix_ids = tokenizer.encode(suffix, add_special_tokens=False)\n",
    "\n",
    "log_prior, grad_log_prior, sample_prior = build_relaxed_single_token_prior(model, tokenizer, device)\n",
    "log_like, grad_log_like = build_suffix_likelihood(model, tokenizer, suffix_ids, device)\n",
    "\n",
    "def log_target(x, sigma):\n",
    "    with torch.no_grad():\n",
    "        return log_like(x) + log_prior(x, sigma)\n",
    "\n",
    "def grad_log_target(x, sigma):\n",
    "    with torch.no_grad():\n",
    "        return grad_log_like(x) + grad_log_prior(x, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \" went to the shop\"\n",
    "suffix_ids = tokenizer.encode(suffix, add_special_tokens=False)\n",
    "\n",
    "log_prior, grad_log_prior, sample_prior = build_relaxed_single_token_prior(model, tokenizer, device)\n",
    "log_like, grad_log_like = build_suffix_likelihood(model, tokenizer, suffix_ids, device)\n",
    "\n",
    "def log_target(x, sigma):\n",
    "    with torch.no_grad():\n",
    "        return log_like(x) + log_prior(x, sigma)\n",
    "        # return log_prior(x, sigma)\n",
    "\n",
    "def grad_log_target(x, sigma):\n",
    "    with torch.no_grad():\n",
    "        return grad_log_like(x) + grad_log_prior(x, sigma)\n",
    "        # return grad_log_prior(x, sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a391929b4f041f9ad8b48d89c33309e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running SMC:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prior(x, sigma0)\n\u001b[1;32m     12\u001b[0m sampler \u001b[38;5;241m=\u001b[39m AnnealedSMC(\n\u001b[1;32m     13\u001b[0m     N\u001b[38;5;241m=\u001b[39mN,\n\u001b[1;32m     14\u001b[0m     x_dim\u001b[38;5;241m=\u001b[39md,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m final_particles \u001b[38;5;241m=\u001b[39m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_initial_particles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_logp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_logp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_log_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_log_target\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cont-prob-inf-llm/algos/annealed_smc.py:151\u001b[0m, in \u001b[0;36mAnnealedSMC.run\u001b[0;34m(self, init_sampler, init_logp, log_target, grad_log_target)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# 2. sequential tempering\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_prev \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_prev \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_target \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mess_tol:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# 2a. adapt σ_t\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     sigma_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapt_sigma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_logp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigma_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msigma_t\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# 2b. weight‐update\u001b[39;00m\n",
      "File \u001b[0;32m~/cont-prob-inf-llm/algos/annealed_smc.py:82\u001b[0m, in \u001b[0;36mAnnealedSMC.adapt_sigma\u001b[0;34m(self, log_target, init_logp)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lo\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# otherwise bisect\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mhi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlo\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mess_tol:\n\u001b[1;32m     83\u001b[0m     mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (hi \u001b[38;5;241m+\u001b[39m lo)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mess_at(mid, log_target, init_logp) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mess_min:\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;66;03m# too aggressive → need smaller step (i.e. larger σ)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "N = 16\n",
    "d = 768 # gpt2 embedding dimension\n",
    "sigma0 = 10.0\n",
    "sigma_target = 0.1\n",
    "\n",
    "def sample_initial_particles(N, d):\n",
    "    return sample_prior(N, sigma0)\n",
    "\n",
    "def initial_logp(x):\n",
    "    return log_prior(x, sigma0)\n",
    "\n",
    "sampler = AnnealedSMC(\n",
    "    N=N,\n",
    "    x_dim=d,\n",
    "    sigma_0=sigma0,\n",
    "    sigma_target=sigma_target,\n",
    "    alpha=0.5,\n",
    "    mala_step_size=0.2,\n",
    "    mala_steps=100,\n",
    "    ess_min_frac=0.5,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "final_particles = sampler.run(\n",
    "    init_sampler=sample_initial_particles,\n",
    "    init_logp=initial_logp,\n",
    "    log_target=log_target,\n",
    "    grad_log_target=grad_log_target\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
